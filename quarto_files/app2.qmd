# Component Analysis Code (PCA and MCA) {#sec-App2 .appendix}

## Module and Data Imports

```{python importsBlock}
#| eval: true
#| echo: true
import pandas as pd, numpy as np, seaborn as sns, matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler

from sklearn.decomposition import PCA

from sklearn.cluster import KMeans

from mpl_toolkits.mplot3d import Axes3D

from sklearn.preprocessing import OneHotEncoder

from prince import MCA

fr = pd.read_csv('../data/final_clean.csv')
```

### Principal Component Analysis

#### Select & Scale Numeric Columns

```{python}
#| eval: true
#| echo: true

columns = [
    #'loan_amount',
    #'property_value',
    'income',
    'interest_rate',
    'total_loan_costs',
    'loan_to_value_ratio',
    #'origination_costs',
    #'discount_points',
    #'lender_credits',
    'loan_term',
    'intro_rate_period',
    'total_units',
    'tract_minority_population_percent',
    'tract_population',
    'tract_to_msa_income_percentage',
    'tract_owner_occupied_units',
    'tract_one_to_four_family_homes',
    'tract_median_age_of_housing_units',
    #'debt_to_income_ratio'
]

X = fr[columns]

X = StandardScaler().fit_transform(X)
```

#### Perform 2D PCA

```{python}
#| eval: true
#| echo: true
pca2d = PCA(n_components=2)
result2d = pd.DataFrame(pca2d.fit_transform(X))
result2d['outcome']  = fr['outcome'].astype(bool)

display(
    np.cumsum(pca2d.explained_variance_) #eigenvalues
)

sns.scatterplot(
    data=result2d,
    x=0,y=1,hue='outcome'
)
np.cumsum(pca2d.explained_variance_ratio_)
```

#### Perform 3D PCA

```{python}
#| eval: true
#| echo: true

pca3d = PCA(n_components=3)
result3d = pd.DataFrame(pca3d.fit_transform(X))
result3d['outcome']  = fr['outcome'].astype(bool)
display(
    np.cumsum(pca3d.explained_variance_) #eigenvalues
)
result3d
np.cumsum(pca3d.explained_variance_ratio_)
```


```{python}
#| eval: true
#| echo: true
fig = plt.figure(figsize=(12,12))
ax = Axes3D(fig,rect=[0,0,.9,1],elev=5,azim=225)

fig.add_axes(ax)

x=result3d[0]
y=result3d[1]
z=result3d[2]

ax.scatter(x,y,z, cmap="RdYlGn", edgecolor='k', s=40, c=fr['outcome'].astype(int))

plt.show()
```


### Multiple Correspondence Analysis

```{python}
#| eval: true
#| echo: true

mapper = {
    'applicant_race':{
        'American Indian/Alaska Native':0b0000000000000000001,
        'Asian':0b0000000000000000010,
        'Asian Indian':0b0000000000000000100,
        'Chinese':0b0000000000000001000,
        'Filipino':0b0000000000000010000,
        'Japanese':0b0000000000000100000,
        'Korean':0b0000000000001000000,
        'Vietnamese':0b0000000000010000000,
        'Other Asian':0b0000000000100000000,
        'Black/African American':0b0000000001000000000,
        'Native Hawaiian/Pacific Islander':0b0000000010000000000,
        'Native Hawaiian':0b0000000100000000000,
        'Guamanian/Chamorro':0b0000001000000000000,
        'Samoan':0b0000010000000000000,
        'Other Pacific Islander':0b0000100000000000000,
        'White':0b0001000000000000000,
        'Information not provided':0b0010000000000000000,
        'Not Applicable':0b0100000000000000000,
        'No Co-applicant':0b1000000000000000000
    },
    'co-applicant_race':{
        'American Indian/Alaska Native':0b0000000000000000001,
        'Asian':0b0000000000000000010,
        'Asian Indian':0b0000000000000000100,
        'Chinese':0b0000000000000001000,
        'Filipino':0b0000000000000010000,
        'Japanese':0b0000000000000100000,
        'Korean':0b0000000000001000000,
        'Vietnamese':0b0000000000010000000,
        'Other Asian':0b0000000000100000000,
        'Black/African American':0b0000000001000000000,
        'Native Hawaiian/Pacific Islander':0b0000000010000000000,
        'Native Hawaiian':0b0000000100000000000,
        'Guamanian/Chamorro':0b0000001000000000000,
        'Samoan':0b0000010000000000000,
        'Other Pacific Islander':0b0000100000000000000,
        'White':0b0001000000000000000,
        'Information not provided':0b0010000000000000000,
        'Not Applicable':0b0100000000000000000,
        'No Co-applicant':0b1000000000000000000
    },
    'applicant_ethnicity':{
        'Hispanic/Latino':0b000000001,
        'Mexican':0b000000010,
        'Puerto Rican':0b000000100,
        'Cuban':0b000001000,
        'Other Hispanic/Latino':0b000010000,
        'Not Hispanic/Latino':0b000100000,
        'Information Not Provided':0b001000000,
        'Not Applicable':0b010000000,
        'No Co-applicant':0b100000000
    },
    'co-applicant_ethnicity':{
        'Hispanic/Latino':0b000000001,
        'Mexican':0b000000010,
        'Puerto Rican':0b000000100,
        'Cuban':0b000001000,
        'Other Hispanic/Latino':0b000010000,
        'Not Hispanic/Latino':0b000100000,
        'Information Not Provided':0b001000000,
        'Not Applicable':0b010000000,
        'No Co-applicant':0b100000000
    },
    'aus':{
        'Desktop Underwriter':0b00000001,
        'Loan Prospector/Product Advisor':0b00000010,
        'TOTAL Scorecard':0b00000100,
        'GUS':0b00001000,
        'Other':0b00010000,
        'Internal Proprietary':0b00100000,
        'Not applicable':0b01000000,
        'Exempt':0b10000000,
    }, 
    # 'denial_reason':{
    #     'DTI':0b0000000001,
    #     'Employment History':0b0000000010,
    #     'Credit History':0b0000000100,
    #     'Collateral':0b0000001000,
    #     'Insufficient Cash':0b0000010000,
    #     'Unverifiable Information':0b0000100000,
    #     'Credit Application Incomplete':0b0001000000,
    #     'Mortgage Insurance Denied':0b0010000000,
    #     'Other':0b0100000000,
    #     'Not Applicable':0b1000000000
    # }
}

new_mapper = {}
for k,v in mapper.items():
    new_mapper[k] = {}
    #print(k)
    for j,w in v.items():
        #print(w,j)
        new_mapper[k][w] = j

#drop balloon payment, interest_only_payment, other_nonamortizing_features
#income_from_median, 

fr.drop(
    labels = [
        'balloon_payment', 
        'interest_only_payment', 
        'other_nonamortizing_features',
        'income_from_median',
        'state_code',
        'county_code'
    ],
    axis=1,inplace=True
)

```


```{python}
#| eval: true
#| echo: true
#adjust numerics to categoricals

numerics = [
    'income',
    'loan_amount',
    'interest_rate',
    'total_loan_costs',
    'origination_charges',
    'discount_points',
    'lender_credits',
    'loan_term',
    'intro_rate_period',
    'property_value',
    'total_units',
    'tract_population',
    'tract_minority_population_percent',
    'ffiec_msa_md_median_family_income',
    'tract_to_msa_income_percentage',
    'tract_owner_occupied_units',
    'tract_one_to_four_family_homes',
    'tract_median_age_of_housing_units',
    'loan_to_value_ratio'
]

bounds = [i/5 for i in range(1,5)]
# print(bounds)
for col in numerics:
    
    if col == 'income':
        fr.loc[fr[col]<=0,col] = 0.01
        fr[col] = np.log(fr[col])

    s = fr[col].std()

    m = fr[col].mean()

    cut_level = [
        m-2*s,
        m-s,
        m+s,
        m+2*s
    ]

    # cut_level = list(np.percentile(fr[col],bounds))
    
    cut_level = [-np.inf] + cut_level + [np.inf]

    print(col)

    print(cut_level)

    fr[col] = pd.cut(
        fr[col],
        bins=cut_level,
        labels=["L","LM","M","HM","H"]
    )

    fr[col] = fr[col].astype('category')

```

```{python}
#| eval: true
#| echo: true

#extract binary to separate frame
fr_bin = fr[[
    'applicant_race',
    'applicant_ethnicity',
    'co-applicant_race',
    'co-applicant_ethnicity',
    #'denial_reason',
    'aus'
]].copy()

for k,v in new_mapper.items():
    for l,w in v.items():
        fr_bin[k+'_'+w] = (fr_bin[k]&l > 0).astype(int)

fr_bin.drop(labels=[    'applicant_race',
    'applicant_ethnicity',
    'co-applicant_race',
    'co-applicant_ethnicity',
    #'denial_reason',
    'aus'],
    inplace=True,
    axis=1
)
fr.drop(
    labels=[
        'applicant_race',
        'applicant_ethnicity',
        'co-applicant_race',
        'co-applicant_ethnicity',
        'denial_reason',
        'aus',
        'outcome',
        'action_taken'
    ],
    inplace=True,
    axis=1
)
```

```{python}
#| eval: true
#| echo: true
# ohe = OneHotEncoder()
# out = ohe.fit_transform(fr)
# # ohe.get_feature_names_out().tolist()
# outdf = pd.DataFrame(out.toarray(),columns=ohe.get_feature_names_out().tolist())
# outdf_nr = outdf.copy()

# for col in fr_bin.columns:
#     outdf[col] = fr_bin[col].copy()

# for col in outdf.columns:
#     outdf[col] = outdf[col].astype(int)
```

```{python}
#| eval: true
#| echo: true
# mca3d = MCA(n_components=3,one_hot=False)
# xform3d = mca3d.fit_transform(outdf.drop(labels=[
#     'applicant_race_No Co-applicant','applicant_ethnicity_No Co-applicant',
#     'aus_GUS','aus_Exempt'
# ],axis=1))
# xform3d.columns = ['PC{}'.format(i+1) for i in range(len(xform3d.columns))]

# mcaNd = MCA(n_components=20,one_hot=False)
# xformNd = mcaNd.fit_transform(outdf.drop(labels=[
#     'applicant_race_No Co-applicant','applicant_ethnicity_No Co-applicant',
#     'aus_GUS','aus_Exempt'
# ],axis=1))
# xformNd.columns = ['PC{}'.format(i+1) for i in range(len(xformNd.columns))]
```



```{python}
#| eval: true
#| echo: true

```


```{python}
#| eval: true
#| echo: true

```


```{python}
#| eval: true
#| echo: true

```




```{python}
#| eval: true
#| echo: true

```